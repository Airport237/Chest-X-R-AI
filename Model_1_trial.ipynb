{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:11:02.305254Z",
     "start_time": "2025-03-20T16:11:02.300900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import load_data\n",
    "from preprocess_data import ChestXRay14"
   ],
   "id": "2429e7bf864337da",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:10:39.556045Z",
     "start_time": "2025-03-20T16:10:39.521005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset using existing functions\n",
    "train_loader, ds_train, ds_test = load_data.get_data()\n",
    "\n",
    "# Check a sample batch\n",
    "for batch in train_loader:\n",
    "    print(f\"Batch image shape: {batch['image'].shape}, Batch label shape: {batch['label'].shape}\")\n",
    "    break"
   ],
   "id": "f9ab1d5a43c7a9b6",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The API for Deep Lake 4.0 has changed significantly, including the `load` method being replaced by `open`. To continue using Deep Lake 3.x, use `pip install \"deeplake<4\"`. For information on migrating your code, see https://docs.deeplake.ai/latest/details/v3_conversion/",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mException\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Load dataset using existing functions\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m train_loader, ds_train, ds_test = \u001B[43mload_data\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Check a sample batch\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Coding/Machine_learning/Chest-X-R-AI/load_data.py:6\u001B[39m, in \u001B[36mget_data\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget_data\u001B[39m():\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m     ds_train = \u001B[43mdeeplake\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhub://activeloop/nih-chest-xray-train\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m     ds_test = deeplake.load(\u001B[33m'\u001B[39m\u001B[33mhub://activeloop/nih-chest-xray-test\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      8\u001B[39m     train_loader = ds_train.pytorch(num_workers=\u001B[32m0\u001B[39m, batch_size=\u001B[32m4\u001B[39m, shuffle=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/Coding/Machine_learning/Chest-X-R-AI/.venv/lib/python3.11/site-packages/deeplake/__init__.py:178\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload\u001B[39m(*args, **kwargs):\n\u001B[32m    175\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    176\u001B[39m \u001B[33;03m    .. deprecated:: 4.0.0\u001B[39;00m\n\u001B[32m    177\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\n\u001B[32m    179\u001B[39m \u001B[38;5;250m        \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    180\u001B[39m \u001B[33;03mThe API for Deep Lake 4.0 has changed significantly, including the `load` method being replaced by `open`.\u001B[39;00m\n\u001B[32m    181\u001B[39m \u001B[33;03mTo continue using Deep Lake 3.x, use `pip install \"deeplake<4\"`.\u001B[39;00m\n\u001B[32m    182\u001B[39m \u001B[33;03mFor information on migrating your code, see https://docs.deeplake.ai/latest/details/v3_conversion/\u001B[39;00m\n\u001B[32m    183\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m.replace(\n\u001B[32m    184\u001B[39m             \u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    185\u001B[39m         ).strip()\n\u001B[32m    186\u001B[39m     )\n",
      "\u001B[31mException\u001B[39m: The API for Deep Lake 4.0 has changed significantly, including the `load` method being replaced by `open`. To continue using Deep Lake 3.x, use `pip install \"deeplake<4\"`. For information on migrating your code, see https://docs.deeplake.ai/latest/details/v3_conversion/"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ChestXRayCNN(nn.Module):\n",
    "    def __init__(self, num_classes=14):\n",
    "        super(ChestXRayCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)  # Assuming input image is resized to 64x64\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # No activation here since we'll use BCEWithLogitsLoss\n",
    "\n",
    "        return x"
   ],
   "id": "ada98f464e67c6e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate model and move to device\n",
    "num_classes = 14\n",
    "model = ChestXRayCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Define loss function (BCEWithLogitsLoss for multilabel classification)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "aaaa8b678bd87a2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, dataloader, criterion, optimizer, device, num_epochs=50):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, device, num_epochs=50)"
   ],
   "id": "a352803f76da83e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].cpu().numpy()  # Convert to numpy\n",
    "\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "            all_labels.append(labels)\n",
    "            all_preds.append(predictions)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "\n",
    "    # Compute AUC-ROC per class\n",
    "    auc_scores = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    print(f\"Mean AUC-ROC: {np.mean(auc_scores):.4f}\")\n",
    "    for i, auc in enumerate(auc_scores):\n",
    "        print(f\"Class {i+1} AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, train_loader, device)"
   ],
   "id": "d74921fd2064611a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
